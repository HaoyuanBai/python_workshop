{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uSPRktGrD5O2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as mp\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gvwr7vktVUC"
   },
   "outputs": [],
   "source": [
    "#dealt with old version of csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "file = 'precisefinal.csv'\n",
    "df = pd.read_csv(file)\n",
    "df['bookid'] = df['bookid'].astype(int)\n",
    "for i in df:\n",
    "    print(i)\n",
    "# file = 'precisefinal.csv'\n",
    "# df = pd.read_csv(file)\n",
    "df['bookid'] = df['bookid'].astype(int)\n",
    "# df['clickTime'] = df['clickTime'].apply(lambda x: process(x))\n",
    "df['clickTime'] = pd.to_datetime(df['clickTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "df['hs_name'] = df['hotspotName'].apply(lambda x: x.split('_')[0])\n",
    "print(df['hs_name'])\n",
    "hs_names = df['hs_name'].unique()\n",
    "\n",
    "for name in hs_names:\n",
    "    if name.startswith('p'):\n",
    "        hs_types = ['quotes', 'vocabulary']\n",
    "        for hs_type in hs_types:\n",
    "            tmp = df.loc[(df['hs_name'] == name) & (df['hotspotType'] == hs_type)].copy()\n",
    "            print(tmp.shape[0])\n",
    "            if tmp.shape[0] > 1:\n",
    "                tmp['diff'] = tmp['clickTime'].diff(1)\n",
    "                tmp['diff'] = tmp['diff'].apply(lambda x: x.total_seconds())\n",
    "                indexes = tmp.loc[(tmp['diff'] >= 0) & (tmp['diff'] <= 2)].index\n",
    "                print(indexes)\n",
    "                df = df.loc[~df.index.isin(indexes)]\n",
    "                \n",
    "for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18,23,29,\n",
    "          30,31,43,45,50,56,57,59,61,64,65,71,72,73,79,81,\n",
    "          83,90,97,100,102,108,114,115,116,121,125,126,\n",
    "          128,13,131,132,134,136,138,140,143,145,146,147,\n",
    "          150,152,154,158,159,160,161,163,164,\n",
    "          167,168,174,184,199,200,201,209,213,215,217,\n",
    "          239,243,251,253,255,257,259,265,267]:\n",
    "    \n",
    "    indexNames = df[ df['username'] == i ].index\n",
    "    # Delete row indexes from dataFrame\n",
    "    df.drop(indexNames , inplace=True)\n",
    "\n",
    "df = df.sort_values(by=['username', 'opentime'])\n",
    "df.to_csv('o.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "7CZo2dsvJBhM"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process(time):\n",
    "    time = time.split()\n",
    "    time[0] = time[0].split('/')\n",
    "    time[0][2] = '20' + time[0][2]\n",
    "    time[0] = '/'.join(time[0])\n",
    "    time = ' '.join(time)\n",
    "    return time\n",
    "\n",
    "def duration(x):\n",
    "    #start time when user read the book(bookid ->0,1) \n",
    "    start_time = x.iloc[0, 3]\n",
    "\n",
    "    #type of the discussion book\n",
    "    type_ = x.iloc[0, 1]\n",
    "\n",
    "    hotspot_name = x.iloc[:, 2]\n",
    "    check = ''\n",
    "    if 'p17_nextButton' in hotspot_name.tolist() or 'q17_nextButton' in hotspot_name.tolist():\n",
    "        check = 'yes'\n",
    "    else:\n",
    "        check = 'no'\n",
    "\n",
    "    q_dura = 0\n",
    "    p_dura = 0\n",
    "    end_time = start_time\n",
    "    for i in range(1, x.shape[0]):\n",
    "        click, name = x.iloc[i, 3], x.iloc[i, 1]\n",
    "        if name == type_:\n",
    "            end_time = click\n",
    "        else:\n",
    "            if type_ == 'q':\n",
    "                q_dura =round(q_dura+((end_time - start_time).total_seconds())/60, 2)\n",
    "            else:\n",
    "                p_dura =round(p_dura+((end_time - start_time).total_seconds())/60, 2)\n",
    "            start_time = click\n",
    "            end_time = click\n",
    "            type_ = name\n",
    "    if type_ == 'q':\n",
    "        q_dura =round(q_dura+((end_time - start_time).total_seconds())/60, 2)\n",
    "    else:\n",
    "        p_dura =round(p_dura+((end_time - start_time).total_seconds())/60, 2)\n",
    "    return q_dura, p_dura, check\n",
    "\n",
    "\n",
    "file = 'newwww_changed.csv'\n",
    "df = pd.read_csv(file)\n",
    "df['bookid'] = df['bookid'].astype(int)\n",
    "\n",
    "\n",
    "# df['clickTime'] = df['clickTime'].apply(lambda x: process(x))\n",
    "df['clickTime'] = pd.to_datetime(df['clickTime'], format='%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "\n",
    "df['date'] = df['clickTime'].apply(lambda x: x.strftime('%Y/%m/%d'))\n",
    "\n",
    "\n",
    "df['name'] = df['hotspotName'].apply(lambda x: x[0])\n",
    "\n",
    "df = df[['username', 'name', 'hotspotName', 'clickTime', 'date', 'bookid']]\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18,23,29,30,31,43,45,50,56,57,59,61,64,65,71,72,73,79,81,\n",
    "          83,90,97,100,102,108,114,115,116,121,125,126,\n",
    "          128,13,131,132,134,136,138,140,143,145,146,147,\n",
    "          150,152,154,158,159,160,161,163,164,227,73,47,144,88,167,168,174,184,199,200,201,209,213,215,217,\n",
    "          239,243,251,253,255,257,259,265,267]:\n",
    "          \n",
    "    indexNames = df[ df['username'] == i ].index\n",
    "    # Delete row indexes from dataFrame\n",
    "    df.drop(indexNames , inplace=True)\n",
    "    \n",
    "    \n",
    "book_id = []\n",
    "username = []\n",
    "q_duration = []\n",
    "p_duration = []\n",
    "dates = []\n",
    "checks = []\n",
    "\n",
    "for user in df['username'].unique():\n",
    "    unique_dates = df.loc[df['username'] == user]['date'].unique()\n",
    "    for date in unique_dates:\n",
    "        tmp = df.loc[(df['username'] == user) & (df['date'] == date)]\n",
    "        q, p, check = duration(tmp)\n",
    "        username.append(user)\n",
    "        q_duration.append(q)\n",
    "        p_duration.append(p)\n",
    "        dates.append(date)\n",
    "        checks.append(check)\n",
    "        book_id.append(tmp['bookid'].iloc[0])\n",
    "\n",
    "result = pd.DataFrame({'username': username, 'Q Clicktime duration': q_duration,\n",
    "                       'P Clicktime duration': p_duration, 'Date': dates, 'Bookid': book_id, 'Check': checks})\n",
    "\n",
    "\n",
    "\n",
    "result.to_csv('time.csv', index=False)\n",
    "\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "#import io\n",
    "#df1=pd.read_csv(io.BytesIO(uploaded['hotspotResult425.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "aDL_C8LTDAF_"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('time.csv')\n",
    "\n",
    "participants = []\n",
    "r1q = []\n",
    "r1p = []\n",
    "r1 = []\n",
    "r2q = []\n",
    "r2p = []\n",
    "r2 = []\n",
    "for user in df['username'].unique():\n",
    "    tmp = df.loc[df['username'] == user]\n",
    "    participants.append(user)\n",
    "    bookids = tmp['Bookid'].unique()\n",
    "    \n",
    "    if bookids.shape[0] == 1:\n",
    "#         print(bookids.shape[0])\n",
    "        if bookids[0] == 0:\n",
    "            r2q.append(0)\n",
    "            r2p.append(0)\n",
    "            r2.append(0)\n",
    "        else:\n",
    "            r1q.append(0)\n",
    "            r1p.append(0)\n",
    "            r1.append(0)\n",
    "\n",
    "    for bookid in bookids:\n",
    "        if bookid == 0:\n",
    "            q_durations = tmp.loc[tmp['Bookid'] == bookid]['Q Clicktime duration'].sum()\n",
    "            p_durations = tmp.loc[tmp['Bookid'] == bookid]['P Clicktime duration'].sum()\n",
    "            r1q.append(q_durations)\n",
    "            r1p.append(p_durations)\n",
    "            r1.append(round(q_durations + p_durations,2))\n",
    "        else:\n",
    "            q_durations = tmp.loc[tmp['Bookid'] == bookid]['Q Clicktime duration'].sum()\n",
    "            p_durations = tmp.loc[tmp['Bookid'] == bookid]['P Clicktime duration'].sum()\n",
    "            r2q.append(q_durations)\n",
    "            r2p.append(p_durations)\n",
    "            r2.append(round(q_durations + p_durations,2))\n",
    "\n",
    "# res = pd.DataFrame({'username': participants, 'R1Q_READ': r1q, 'R1P_READ': r1p, 'R1_READ': r1,\n",
    "#                     'R2Q_READ': r2q, 'R2P_READ': r2p, 'R2_READ': r2})\n",
    "# res['T_READ'] = round(res['R1_READ'] + res['R2_READ'],2)\n",
    "# res.to_csv('lit.csv', index=False)\n",
    "res = pd.DataFrame({'username': participants, 'discstime_r1': r1q, 'readtime_r1': r1p, 'R1_total': r1,\n",
    "                    'discstime_r2': r2q, 'readtime_r2': r2p, 'R2_total': r2})\n",
    "res['TOTOL_READ'] = round(res['R1_total'] + res['R2_total'],2)\n",
    "res.to_csv('lit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "shNrx4imDChN"
   },
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "df = pd.read_csv('newwww_changed.csv')\n",
    "df2 = pd.read_csv('newwww_changed.csv')\n",
    "df2.drop(df.index, inplace=True)\n",
    "indexDate = parser.parse(\"Aug 28 1980\")\n",
    "indexUser = 9999999999\n",
    "for row in df.iterrows():\n",
    "    date = parser.parse(row[1][2]).date()\n",
    "    if date != indexDate and row[1][1] != indexUser:\n",
    "#         print(indexUser)\n",
    "#         print(indexDate)\n",
    "#         print(row[1][1])\n",
    "#         print(date)\n",
    "        indexUser = row[1][1]\n",
    "        indexDate = date\n",
    "        df2 = df2.append(row[1])\n",
    "    elif date == indexDate and row[1][1] == indexUser:\n",
    "        df2 = df2.append(row[1])\n",
    "\n",
    "df2.to_csv(\"1.csv\",index=False)\n",
    "\n",
    "\n",
    "with open('1.csv', 'r') as t1, open('newwww_changed.csv', 'r') as t2:\n",
    "    fileone = t1.readlines()\n",
    "    filetwo = t2.readlines()\n",
    "\n",
    "with open('2.csv', 'w') as outFile:\n",
    "    for line in filetwo:\n",
    "        if line not in fileone:\n",
    "            outFile.write(line)\n",
    "df = pd.read_csv('2.csv')         \n",
    "df.to_csv(\"2.csv\", header=['bookid','username',\t'opentime',\t'closetime','hotspotName','hotspotType','clickResult','clickTime','remarks','hs_name'], index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrpuWetj5mv5"
   },
   "source": [
    "Correctness+Question Answered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "m_72GewPI2Qs"
   },
   "outputs": [],
   "source": [
    "#必要的package\n",
    "import pandas as pd\n",
    "import numpy as mp\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "VwnFQoQuEJCk"
   },
   "outputs": [],
   "source": [
    "#导入文件\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv (\"1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "1JTDqGPY5td1"
   },
   "outputs": [],
   "source": [
    "#拿出userId\n",
    "userList = []\n",
    "for i in df1[\"username\"]:\n",
    "    if i not in userList:\n",
    "        userList.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "9QTbVg5t5tnB"
   },
   "outputs": [],
   "source": [
    "#新建两个空的dic, dic1用来放每个学生 实际做了几个选择题的数量， dic2用来放每个学生 第一次就选择了正确的答案的数量\n",
    "dic_1={}\n",
    "dic_2={}\n",
    "\n",
    "\n",
    "for i in userList:\n",
    "    dic_1[i]=0\n",
    "    dic_2[i]=0\n",
    "    #把每个学生所有的数据分别拿出来\n",
    "    student0 = df1[df1.username == int(i)]\n",
    "    #新建空的list2用于后面放题号\n",
    "    list2=[]\n",
    "    #新建count_right 用于后面计算第一次就选择了正确答案的数量\n",
    "    count_right=0\n",
    "    for index, row in student0.iterrows():\n",
    "        #把每一行拿出来\n",
    "        a=row\n",
    "        #如果是discussion类型，就代表是多选题\n",
    "        if a.hotspotType==\"discussion\":\n",
    "            #name 是题号\n",
    "            name=a.hotspotName\n",
    "            name=str(name)[1:]\n",
    "            #如果题号没有被记录\n",
    "            if name not in list2:\n",
    "                #把题号放进list\n",
    "                list2.append(name)\n",
    "                #看第一遍result 是否是对的，对的就次数加一\n",
    "                result=str(a.clickResult)\n",
    "                if result.endswith(\"answer\"):\n",
    "                    count_right+=1\n",
    "    dic_1[i]=len(list2)\n",
    "    dic_2[i]=count_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "dw6KM1As5tpO"
   },
   "outputs": [],
   "source": [
    "#算正确率， 保留三位小数\n",
    "dic_rate={}\n",
    "for i in userList:\n",
    "    i=int(i)\n",
    "    #判断 实际选择题次数是否为0， 为0的话直接算0\n",
    "    if dic_1[i]==0:\n",
    "        dic_rate[i]=0\n",
    "    else:\n",
    "        #用正确率/次数， 保留三位小数\n",
    "        dic_rate[i]=round(dic_2[i]/dic_1[i],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "Y0KxaHL05trZ"
   },
   "outputs": [],
   "source": [
    "#a是userID, b是每个学生实际做了几个选择题的数量， c是每个学生第一次就选择了正确的答案的数量, d是c/b-Right Rate\n",
    "a=userList\n",
    "b=list(dic_1.values())\n",
    "c=list(dic_2.values())\n",
    "d=list(dic_rate.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "RsIRydnB5y8U"
   },
   "outputs": [],
   "source": [
    "#改成dataframe格式\n",
    "df3 = pd.DataFrame({'UserName' : a,'NumQuestionAnswer':b, 'NumRightFirstly' : c,'RightRate':d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "dDZv8arL5y-y"
   },
   "outputs": [],
   "source": [
    "#导出文件\n",
    "df3.to_csv('RightRate1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0573fiuH5zA5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv (\"RightRate1.csv\")\n",
    "df2 = pd.read_csv (\"RightRate2.csv\")\n",
    "\n",
    "\n",
    "df =pd.merge(df1, df2, how='inner', on=['UserName'])\n",
    "df.to_csv('df.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "final = []\n",
    "with open(\"time.csv\") as f:\n",
    "    \n",
    "    reader = csv.reader(f)\n",
    "    i =0\n",
    "    for row in reader:\n",
    "        if i % 2 == 0:\n",
    "            newRow = row\n",
    "            \n",
    "        else:\n",
    "            newRow = newRow + row\n",
    "#             print(newRow)\n",
    "            \n",
    "            final.append(newRow)\n",
    "        i = i + 1\n",
    "head = ['username',\t'Q1 Clicktime duration',\t'P1 Clicktime duration',\t'Date1',\t'Bookid1','Check1',\n",
    "       'username2',\t'Q2 Clicktime duration',\t'P2 Clicktime duration',\t'Date2',\t'Bookid2','Check2']  \n",
    "with open(\"time_update_file.csv\",'w') as f1:\n",
    "      \n",
    "    write = csv.writer(f1)\n",
    "    write.writerow(head)\n",
    "    write.writerows(final)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_be_removed = ['username2']\n",
    "\n",
    "# data = pd.read_csv('time_update_file.csv').drop(columns_to_be_removed, axis = 'columns')\n",
    "\n",
    "\n",
    "# # keep_col =['username',\t'Q1 Clicktime duration','P1 Clicktime duration','Date1',\t'Bookid1','Check1',\n",
    "# #      'Q2 Clicktime duration',\t'P2 Clicktime duration',\t'Date2',\t'Bookid2','Check2']  \n",
    "# # new_f.to_csv(\"time_date_check_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv (\"time_update_file.csv\")\n",
    "df2 = pd.read_csv (\"lit.csv\")\n",
    "\n",
    "\n",
    "df =pd.merge(df1, df2 ,on=['username'])\n",
    "df.to_csv('dfinal.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv (\"ordf.csv\")\n",
    "\n",
    "# df = df.drop_duplicates()\n",
    "# for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18,23,29,30,31,43,45,50,56,57,59,61,64,65,71,72,73,79,81,\n",
    "#           83,90,97,100,102,108,114,115,116,121,125,126,\n",
    "#           128,13,131,132,134,136,138,140,143,145,146,147,\n",
    "#           150,152,154,158,159,160,161,163,164,\n",
    "#           167,168,174,184,199,200,201,209,213,215,217,\n",
    "#           239,243,251,253,255,257,259,265,267,   227,73,47,144,88]:\n",
    "          \n",
    "#     indexNames = df[ df['username'] == i ].index\n",
    "#     df.drop(indexNames , inplace=True)\n",
    "#     indexNames = df[ df['username'] == 227 ].index\n",
    "#     df.drop(indexNames , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227, 73, 47, 144, 88]\n"
     ]
    }
   ],
   "source": [
    "# i = [16,19,20,21,22,24,25,26,27,28,32,33,34,35,36,37,38,39,40,41,42,44,46,48,49,51,52,53,54,55,60,62,63,66,67,68,69,70,74,75,76,77,78,80,82,84,85,86,87,89,91,92,94,95,99,101,103,104,105,106,107,109,110,111,112,113,117,118,119,120,122,123,124,127,129,130,133,135,137,139,141,142,148,149,151,153,155,156,157,162,165,166,169,171,173,175,177,179,181,183,185,187,188,189,191,193,195,196,197,202,203,205,207,211,219,221,223,225,229,231,233,235,237,241,245,247,249,261,263,269,271]\n",
    "# o=  [16,19,20,21,22,24,25,26,27,28,32,33,34,35,36,37,38,39,40,41,42,44,46,47,48,49,51,52,53,54,55,60,62,63,66,67,68,69,70,73,74,75,76,77,78,80,82,84,85,86,87,88,89,91,92,94,95,99,101,103,104,105,106,107,109,110,111,112,113,117,118,119,120,122,123,124,127,129,130,133,135,137,139,141,142,144,149,151,153,155,156,157,162,165,166,169,171,173,175,177,179,181,183,185,187,188,189,191,193,195,196,197,202,203,205,207,211,219,221,223,225,227,229,231,233,235,237,241,245,247,249,261,263,269,271]\n",
    "# print(list(set(o) - set(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cleanstream.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
